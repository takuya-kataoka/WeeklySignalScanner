import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import glob
import os
import yfinance as yf
from pathlib import Path
import math
import datetime
import re

st.set_page_config(page_title="é€±è¶³ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼", layout="wide")

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¡¨ç¤º: ãƒ«ãƒ¼ãƒˆã® VERSION ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦å‹•çš„ã«è¡¨ç¤ºã™ã‚‹
version = "1.00"
try:
    # base_dir ã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆWeeklySignalScanner-mainï¼‰
    repo_root = base_dir.parent
    version_path = repo_root / 'VERSION'
    if version_path.exists():
        version = version_path.read_text(encoding='utf-8').strip()
except Exception:
    pass

st.title(f"ğŸ“ˆ é€±è¶³ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ - MA52 & é™½ç·šåŒ…ã¿è¶³ ver1.02")

# ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ˜ç¤ºï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®é…ç½®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåŸºæº–ã«ã™ã‚‹ï¼‰
base_dir = Path(__file__).resolve().parent

# ãƒ‡ãƒã‚¤ã‚¹é¸æŠ: PC / Mobileï¼ˆUI ã®ã‚µã‚¤ã‚ºèª¿æ•´ã«ä½¿ã†ï¼‰
device_mode = st.sidebar.selectbox('è¡¨ç¤ºãƒ‡ãƒã‚¤ã‚¹', ['PC', 'Mobile'], index=0)
IS_MOBILE = (device_mode == 'Mobile')

# ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–CSSã‚’æŒ¿å…¥ï¼ˆãƒ¢ãƒã‚¤ãƒ«å‘ã‘ã«ãƒ•ã‚©ãƒ³ãƒˆã‚„ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª¿æ•´ï¼‰
if IS_MOBILE:
    st.markdown(
        """
        <style>
        /* Mobile adjustments */
        .stApp .block-container { padding: 0.6rem 0.6rem !important; max-width: 100% !important; }
        .stApp h1 { font-size: 1.4rem !important; }
        .stApp h2, .stApp h3 { font-size: 1.05rem !important; }
        .stApp p, .stApp label, .stApp .stText { font-size: 1.0rem !important; }
        .stButton>button { padding: 0.4rem 0.8rem !important; font-size: 1.0rem !important; }
        .css-1d391kg { margin: 0 !important; }
        </style>
        """,
        unsafe_allow_html=True,
    )
else:
    st.markdown(
        """
        <style>
        /* Desktop: constrain content width for readability */
        .stApp .block-container { max-width: 1200px !important; }
        </style>
        """,
        unsafe_allow_html=True,
    )

# çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆä»»æ„ã® CSV ã‚’é¸ã¹ã‚‹ã‚ˆã†ã«å¤‰æ›´ï¼‰
results_dir = base_dir / 'outputs' / 'results'
# æœ€æ–°ã®æ›´æ–°æ—¥æ™‚ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã« modification time (mtime) ã§ã‚½ãƒ¼ãƒˆ
all_files = sorted(results_dir.glob('*.csv'), key=lambda p: p.stat().st_mtime, reverse=True) if results_dir.exists() else []

if not all_files:
    st.error("çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    st.stop()

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…¨éŠ˜æŸ„ã®æ˜‡é †ã‚½ãƒ¼ãƒˆç‰ˆãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆã—ã¦é¸æŠ
default_index = 0
for i, f in enumerate(all_files):
    name = f.name
    if 'å…¨éŠ˜æŸ„' in name and 'sorted_asc' in name:
        default_index = i
        break

selected_file = st.sidebar.selectbox(
    "çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
    all_files,
    index=default_index,
    format_func=lambda x: x.name
)

# ç®¡ç†ãƒ‘ãƒãƒ«: ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ / æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ / äºˆæƒ³ãƒšãƒ¼ã‚¸èµ·å‹•
with st.sidebar.expander("ç®¡ç†: ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ã‚¹ã‚­ãƒ£ãƒ³ãƒ»äºˆæƒ³", expanded=False):
    st.write("ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚„ã‚¹ã‚­ãƒ£ãƒ³ã€äºˆæƒ³ãƒšãƒ¼ã‚¸èµ·å‹•ãŒã§ãã¾ã™")

    fetch_period = st.text_input('fetch period (yfinance)', value='1y')
    fetch_interval = st.text_input('fetch interval', value='1d')
    fetch_batch = st.number_input('batch size', min_value=1, value=200)
    fetch_sleep = st.number_input('sleep between batches (s)', min_value=0.0, value=1.0, step=0.1)
    fetch_start = st.number_input('start code (4-digit)', min_value=0, value=1300)
    fetch_end = st.number_input('end code (4-digit)', min_value=0, value=9999)

    # æ‰‹å‹•ãƒ†ã‚£ãƒƒã‚«ãƒ¼å…¥åŠ›ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
    manual_tickers = st.text_input('æ‰‹å‹•ãƒ†ã‚£ãƒƒã‚«ãƒ¼ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ä¾‹: 7201,7202 ã¾ãŸã¯ 7201.T,7202.T)', value='')

    # é™¤å¤–ãƒªã‚¹ãƒˆã‚’ç„¡è¦–ã—ã¦å–å¾—ã™ã‚‹ã‹
    allow_excluded = st.checkbox('é™¤å¤–ãƒªã‚¹ãƒˆã‚’ç„¡è¦–ã—ã¦å–å¾— (EXCLUDED ã‚’å«ã‚ã‚‹)', value=False)

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‹•ä½œ: data/ ã®æ—¢å­˜éŠ˜æŸ„ã®ã¿ã€å·®åˆ†ã€ã¾ãŸã¯ç¯„å›²å†…å…¨ä»¶ã‚’é¸æŠ
    fetch_mode = st.selectbox('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡', [
        'data ã«å­˜åœ¨ã™ã‚‹éŠ˜æŸ„ã®ã¿å–å¾—ï¼ˆæ—¢å­˜éŠ˜æŸ„ã‚’å†å–å¾—ï¼‰',
        'ä»Šæ—¥ã®æ—¥ä»˜ãŒç„¡ã„ã‚‚ã®ã ã‘å–å¾—ï¼ˆå·®åˆ†æ›´æ–°ï¼‰',
        'ã™ã¹ã¦ã®éŠ˜æŸ„ã‚’å–å¾—ï¼ˆç¯„å›²å†…å…¨ä»¶ï¼‰'
    ])
    if st.button('ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰'):
        import data_fetcher
        from data_fetcher import load_ticker_from_cache, fetch_and_save_list
        import pandas as _pd

        # ç¯„å›²ï¼ˆstart/endï¼‰ã¯å…±é€š
        start_code = int(fetch_start)
        end_code = int(fetch_end)

        # å€™è£œã®æ§‹ç¯‰
        candidates = []
        data_dir = 'data'

        # å„ªå…ˆ: æ‰‹å‹•ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ã†
        if manual_tickers and manual_tickers.strip():
            parts = [p.strip() for p in re.split('[,\n;]+', manual_tickers) if p.strip()]
            parsed = []
            for p in parts:
                token = p
                # æ•°å€¤ã®ã¿ãªã‚‰ 4 æ¡ã‚¼ãƒ­åŸ‹ã‚ã—ã¦ .T ã‚’ä»˜ä¸
                if re.fullmatch(r"\d{1,4}", token):
                    token = f"{int(token):04d}.T"
                else:
                    if not token.upper().endswith('.T'):
                        token = token.upper()
                parsed.append(token)
            candidates = parsed
        else:
            if fetch_mode.startswith('ã™ã¹ã¦ã®éŠ˜æŸ„'):
                # ç¯„å›²å†…ã®å…¨éŠ˜æŸ„ã‚’å¯¾è±¡ã«ã™ã‚‹
                candidates = [f"{i:04d}.T" for i in range(start_code, end_code + 1)]
                if not allow_excluded:
                    try:
                        excluded = getattr(data_fetcher, 'EXCLUDED_TICKERS', set())
                        candidates = [t for t in candidates if t not in excluded]
                    except Exception:
                        pass
            else:
                # data/ ã«å­˜åœ¨ã™ã‚‹éŠ˜æŸ„ã®ã¿ã‚’å€™è£œã¨ã™ã‚‹
                tickers_from_data = []
                if os.path.isdir(data_dir):
                    for fn in os.listdir(data_dir):
                        if fn.endswith('.parquet'):
                            ticker = os.path.splitext(fn)[0]
                            try:
                                code = int(ticker.replace('.T', ''))
                            except Exception:
                                continue
                            tickers_from_data.append(ticker)
                tickers_from_data = sorted(set(tickers_from_data))
                candidates = [t for t in tickers_from_data if start_code <= int(t.replace('.T','')) <= end_code]

        if not candidates:
            st.info('å–å¾—å¯¾è±¡ã®éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆç¯„å›²ã‚„ data/ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰')
            st.stop()

        targets = []
        today = _pd.Timestamp.today().normalize()
        if fetch_mode.startswith('data ã«å­˜åœ¨ã™ã‚‹'):
            targets = candidates
        elif fetch_mode.startswith('ä»Šæ—¥ã®æ—¥ä»˜ãŒç„¡ã„'):
            for t in candidates:
                df = load_ticker_from_cache(t, cache_dir='data')
                if df is None:
                    targets.append(t)
                    continue
                try:
                    last = _pd.to_datetime(df.index.max()).normalize()
                    if last < today:
                        targets.append(t)
                except Exception:
                    targets.append(t)
        else:
            # ã™ã¹ã¦ã®éŠ˜æŸ„ãƒ¢ãƒ¼ãƒ‰
            targets = candidates

        if not targets:
            st.info('å–å¾—å¯¾è±¡ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆã™ã§ã«æœ€æ–°ï¼‰')
        else:
            with st.spinner(f'å–å¾—ä¸­... {len(targets)} éŠ˜æŸ„'):
                try:
                    # allow_excluded ã‚’ fetch ã«æ¸¡ã™
                    fetch_and_save_list(targets, batch_size=int(fetch_batch), period=fetch_period, interval=fetch_interval, out_dir='data', retry_count=1, sleep_between_batches=float(fetch_sleep), allow_excluded=allow_excluded, verbose=True)
                    st.success('ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†')
                except Exception as e:
                    st.error(f'ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}')

    # åŒ…ã¿è¶³åˆ¤å®šã‚’ç·©å’Œã™ã‚‹ã‹ï¼ˆãƒã‚§ãƒƒã‚¯æ™‚ã®ã¿ç·©å’Œï¼‰ - ã‚¹ã‚­ãƒ£ãƒ³ãƒœã‚¿ãƒ³è¿‘ãã«é…ç½®
    relax_engulfing = st.checkbox('åŒ…ã¿è¶³åˆ¤å®šã‚’ç·©å’Œã™ã‚‹ï¼ˆãƒã‚§ãƒƒã‚¯æ™‚ã®ã¿æœ‰åŠ¹ï¼‰', value=False)

    # æŠ½å‡ºå¯¾è±¡æ—¥æŒ‡å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³: æŒ‡å®šæ—¥ã§ã®åˆ¤å®šã‚’è¡Œã†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å½“æ—¥ï¼‰
    use_as_of_date = st.checkbox('æŠ½å‡ºå¯¾è±¡æ—¥ã‚’æŒ‡å®šã™ã‚‹ï¼ˆæŒ‡å®šãŒç„¡ã‘ã‚Œã°æœ€æ–°ç‰ˆï¼‰', value=False)
    as_of_date = None
    if use_as_of_date:
        today = datetime.date.today()
        as_of_date = st.date_input('æŠ½å‡ºå¯¾è±¡æ—¥', value=today)

    if st.button('æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆã‚¹ã‚­ãƒ£ãƒ³ï¼‰'):
        # å®Ÿè¡Œã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚å®Ÿè¡Œä¸­ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        import scan_all_jp_batch
        with st.spinner('ã‚¹ã‚­ãƒ£ãƒ³ä¸­... data/ ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ã£ã¦å‡¦ç†ã—ã¾ã™'):
            try:
                # pass as-of date when user enabled it
                if use_as_of_date and as_of_date:
                    scan_all_jp_batch.main(relaxed_engulfing=relax_engulfing, as_of_date=str(as_of_date))
                else:
                    scan_all_jp_batch.main(relaxed_engulfing=relax_engulfing)
                st.success('ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: outputs/results ã‚’ç¢ºèªã—ã¦ãã ã•ã„')
                # Streamlit Cloud ä¸Šã§ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚’ãƒªãƒã‚¸ãƒˆãƒªã«ã‚³ãƒŸãƒƒãƒˆã—ã¦ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹å‡¦ç†
                try:
                    import subprocess, datetime

                    st.sidebar.info('ã‚¹ã‚­ãƒ£ãƒ³å®Œäº† â€” Git ã«ã‚³ãƒŸãƒƒãƒˆã‚’è©¦è¡Œã—ã¾ã™')

                    repo_root = base_dir.parent
                    # git ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ç’°å¢ƒå´ã§ä¸Šæ›¸ãã—ã¦ãã ã•ã„ï¼‰
                    subprocess.run(['git', '-C', str(repo_root), 'config', 'user.email', 'streamlit@example.com'], check=False)
                    subprocess.run(['git', '-C', str(repo_root), 'config', 'user.name', 'StreamlitAutoCommit'], check=False)

                    # ã‚¹ã‚­ãƒ£ãƒ³çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ï¼ˆCSV ç­‰ã™ã¹ã¦ï¼‰
                    try:
                        # add each file under results with -f to override .gitignore if needed
                        added_any = False
                        for p in sorted(results_dir.rglob('*')):
                            if p.is_file():
                                relp = os.path.relpath(str(p), start=str(repo_root))
                                add_proc = subprocess.run(['git', '-C', str(repo_root), 'add', '-f', relp], capture_output=True, text=True)
                                st.sidebar.info(f'git add {relp} -> returncode={add_proc.returncode} stderr:{add_proc.stderr}')
                                if add_proc.returncode == 0:
                                    added_any = True
                        if not added_any:
                            st.sidebar.info('outputs/results å†…ã«ã‚¹ãƒ†ãƒ¼ã‚¸å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆ.gitignore ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰')
                    except Exception as e:
                        st.sidebar.error(f'git add å®Ÿè¡Œä¸­ã«ä¾‹å¤–: {e}')

                    # commit å‰ã« VERSION ã‚’è‡ªå‹•ãƒãƒ³ãƒ—ã—ã¦ã‚¹ãƒ†ãƒ¼ã‚¸ã™ã‚‹
                    try:
                        bump_script = repo_root / 'scripts' / 'bump_version.py'
                        if bump_script.exists():
                            subprocess.run(['python3', str(bump_script)], check=False)
                            subprocess.run(['git', '-C', str(repo_root), 'add', 'VERSION'], check=False)
                    except Exception:
                        pass

                    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±å–å¾—ï¼ˆã‚ã‚Œã°ï¼‰
                    version_str = ''
                    try:
                        vpath = repo_root / 'VERSION'
                        if vpath.exists():
                            version_str = vpath.read_text(encoding='utf-8').strip()
                    except Exception:
                        version_str = ''

                    commit_msg = f"chore(scan): add scan results{' ver'+version_str if version_str else ''} {datetime.datetime.utcnow().isoformat()}"
                    commit_proc = subprocess.run(['git', '-C', str(repo_root), 'commit', '-m', commit_msg], capture_output=True, text=True)
                    st.sidebar.info(f'git commit returncode={commit_proc.returncode}\nstdout:{commit_proc.stdout}\nstderr:{commit_proc.stderr}')
                    if commit_proc.returncode != 0:
                        # å¤‰æ›´ãŒç„¡ã‘ã‚Œã°ã‚³ãƒŸãƒƒãƒˆã¯å¤±æ•—ï¼ˆä½•ã‚‚ to commitï¼‰ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§æƒ…å ±ã‚’å‡ºã™
                        if 'nothing to commit' in (commit_proc.stdout + commit_proc.stderr).lower():
                            st.sidebar.info('ã‚³ãƒŸãƒƒãƒˆã™ã‚‹å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆæ—¢ã«æœ€æ–°ã®å¯èƒ½æ€§ï¼‰')
                        else:
                            st.sidebar.error('git commit ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')
                    else:
                        # ãƒ—ãƒƒã‚·ãƒ¥
                        try:
                            # Try to use token from environment or Streamlit secrets if available
                            token = os.environ.get('GITHUB_TOKEN')
                            try:
                                # Streamlit secrets (if deployed with secrets)
                                if not token:
                                    token = st.secrets.get('GITHUB_TOKEN') if hasattr(st, 'secrets') and 'GITHUB_TOKEN' in st.secrets else None
                            except Exception:
                                pass

                            if token:
                                # get origin URL and construct authenticated push URL without logging token
                                rem = subprocess.run(['git', '-C', str(repo_root), 'remote', 'get-url', 'origin'], capture_output=True, text=True)
                                origin_url = rem.stdout.strip()
                                if origin_url.startswith('https://'):
                                    auth_url = origin_url.replace('https://', f'https://{token}@')
                                else:
                                    auth_url = origin_url
                                push_proc = subprocess.run(['git', '-C', str(repo_root), 'push', auth_url, 'main'], capture_output=True, text=True, timeout=120)
                            else:
                                push_proc = subprocess.run(['git', '-C', str(repo_root), 'push', 'origin', 'main'], capture_output=True, text=True, timeout=120)

                            st.sidebar.info(f'git push returncode={push_proc.returncode}\nstdout:{push_proc.stdout}\nstderr:{push_proc.stderr}')
                            if push_proc.returncode == 0:
                                st.sidebar.success('ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚’ origin/main ã«ã‚³ãƒŸãƒƒãƒˆï¼†ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ')
                            else:
                                st.sidebar.error(f'git push ã«å¤±æ•—ã—ã¾ã—ãŸ: {push_proc.stderr}\nèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚')
                        except Exception as e:
                            st.sidebar.error(f'git push å®Ÿè¡Œä¸­ã«ä¾‹å¤–: {e}')
                except Exception as e:
                    st.sidebar.error(f'è‡ªå‹•ã‚³ãƒŸãƒƒãƒˆä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}')
            except Exception as e:
                st.error(f'ã‚¹ã‚­ãƒ£ãƒ³ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}')

    # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ UI
    with st.expander('ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†: outputs/results ã®å‰Šé™¤', expanded=False):
        try:
            repo_root = base_dir.parent
            files = sorted(results_dir.glob('*.csv'), key=lambda p: p.stat().st_mtime, reverse=True) if results_dir.exists() else []
            file_names = [p.name for p in files]
            to_delete = st.multiselect('å‰Šé™¤ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ', file_names)
            if to_delete:
                if st.button('é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤'):
                    import subprocess, datetime
                    st.sidebar.info('é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™...')
                    removed = []
                    for name in to_delete:
                        p = results_dir / name
                        relp = os.path.relpath(str(p), start=str(repo_root))
                        try:
                            # Try git rm -f to stage deletion for tracked files
                            rm_proc = subprocess.run(['git', '-C', str(repo_root), 'rm', '-f', relp], capture_output=True, text=True)
                            st.sidebar.info(f'git rm {name} -> returncode={rm_proc.returncode} stderr:{rm_proc.stderr}')
                            if rm_proc.returncode != 0:
                                # fallback: remove file and stage
                                if p.exists():
                                    p.unlink()
                                add_proc = subprocess.run(['git', '-C', str(repo_root), 'add', '-A'], capture_output=True, text=True)
                                st.sidebar.info(f'git add -A -> returncode={add_proc.returncode} stderr:{add_proc.stderr}')
                            removed.append(name)
                        except Exception as e:
                            st.sidebar.error(f'ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ä¸­ã«ä¾‹å¤–: {e}')

                    if removed:
                        # bump VERSION and stage it
                        try:
                            bump_script = repo_root / 'scripts' / 'bump_version.py'
                            if bump_script.exists():
                                subprocess.run(['python3', str(bump_script)], check=False)
                                subprocess.run(['git', '-C', str(repo_root), 'add', 'VERSION'], check=False)
                        except Exception:
                            pass

                        # Commit
                        version_str = ''
                        try:
                            vpath = repo_root / 'VERSION'
                            if vpath.exists():
                                version_str = vpath.read_text(encoding='utf-8').strip()
                        except Exception:
                            version_str = ''

                        commit_msg = f"chore(clean): remove results {','.join(removed)}{' ver'+version_str if version_str else ''} {datetime.datetime.utcnow().isoformat()}"
                        commit_proc = subprocess.run(['git', '-C', str(repo_root), 'commit', '-m', commit_msg], capture_output=True, text=True)
                        st.sidebar.info(f'git commit returncode={commit_proc.returncode}\nstdout:{commit_proc.stdout}\nstderr:{commit_proc.stderr}')
                        # Push (use token if available)
                        try:
                            token = os.environ.get('GITHUB_TOKEN')
                            try:
                                if not token:
                                    token = st.secrets.get('GITHUB_TOKEN') if hasattr(st, 'secrets') and 'GITHUB_TOKEN' in st.secrets else None
                            except Exception:
                                pass

                            if token:
                                rem = subprocess.run(['git', '-C', str(repo_root), 'remote', 'get-url', 'origin'], capture_output=True, text=True)
                                origin_url = rem.stdout.strip()
                                if origin_url.startswith('https://'):
                                    auth_url = origin_url.replace('https://', f'https://{token}@')
                                else:
                                    auth_url = origin_url
                                push_proc = subprocess.run(['git', '-C', str(repo_root), 'push', auth_url, 'main'], capture_output=True, text=True, timeout=120)
                            else:
                                push_proc = subprocess.run(['git', '-C', str(repo_root), 'push', 'origin', 'main'], capture_output=True, text=True, timeout=120)

                            st.sidebar.info(f'git push returncode={push_proc.returncode}\nstdout:{push_proc.stdout}\nstderr:{push_proc.stderr}')
                            if push_proc.returncode == 0:
                                st.sidebar.success('é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã‚’ã‚³ãƒŸãƒƒãƒˆï¼†ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ')
                            else:
                                st.sidebar.error('git push ã«å¤±æ•—ã—ã¾ã—ãŸã€‚èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')
                        except Exception as e:
                            st.sidebar.error(f'git push å®Ÿè¡Œä¸­ã«ä¾‹å¤–: {e}')
        except Exception:
            st.error('ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ')

    st.write('---')
    st.write('äºˆæƒ³ãƒšãƒ¼ã‚¸èµ·å‹•ï¼ˆå¤–éƒ¨Streamlitã‚’åˆ¥ãƒãƒ¼ãƒˆã§èµ·å‹•ï¼‰')
    app_options = {
        'æ—¢å­˜: app_predict.py': 'app_predict.py',
        'æ–°è¦: è¡€çµ±äºˆæƒ³ app (streamlit_horse_app.py)': 'streamlit_horse_app.py'
    }
    chosen_label = st.selectbox('èµ·å‹•ã™ã‚‹ã‚¢ãƒ—ãƒªã‚’é¸æŠ', list(app_options.keys()))
    chosen_app = app_options[chosen_label]
    chosen_port = st.number_input('èµ·å‹•ãƒãƒ¼ãƒˆ', min_value=1024, max_value=65535, value=8502)
    if st.button('é¸æŠã‚¢ãƒ—ãƒªã‚’èµ·å‹•'):
        import subprocess, os
        out_log = str(base_dir / 'outputs' / f'streamlit_{chosen_port}.log')
        os.makedirs(str(base_dir / 'outputs'), exist_ok=True)
        streamlit_bin = os.path.abspath('/workspaces/WeeklySignalScanner-main/.venv/bin/streamlit')
        app_path = os.path.abspath(base_dir / chosen_app)
        cmd = f"nohup env STREAMLIT_BROWSER_GUESSING=false STREAMLIT_DISABLE_TELEMETRY=1 {streamlit_bin} run {app_path} --server.port {chosen_port} --server.headless true > {out_log} 2>&1 &"
        try:
            subprocess.Popen(cmd, shell=True, cwd=os.getcwd())
            st.info(f'èµ·å‹•ã‚³ãƒãƒ³ãƒ‰ã‚’é€ä¿¡ã—ã¾ã—ãŸ: {chosen_app} -> http://localhost:{chosen_port}')
            st.write('Local URL:', f'http://localhost:{chosen_port}')
            st.write(f'ãƒ­ã‚°: {out_log}')
        except Exception as e:
            st.error(f'äºˆæƒ³ãƒšãƒ¼ã‚¸èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}')

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆå…ˆé ­ã« retrieved_at ãƒ¡ã‚¿è¡ŒãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
def read_maybe_timestampped_csv(path):
    try:
        with open(path, 'r', encoding='utf-8') as fh:
            first = fh.readline()
        if first.startswith('retrieved_at,'):
            return pd.read_csv(path, skiprows=1)
        return pd.read_csv(path)
    except Exception:
        return pd.read_csv(path)

df = read_maybe_timestampped_csv(selected_file)

# è¡¨ç¤º: çµæœãƒ•ã‚¡ã‚¤ãƒ«ã¨ data ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æœ€çµ‚æ›´æ–°æ™‚åˆ»ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤º
try:
    sel_mtime = datetime.datetime.fromtimestamp(Path(str(selected_file)).stat().st_mtime)
    sel_mtime_str = sel_mtime.strftime("%Y-%m-%d %H:%M:%S")
except Exception:
    sel_mtime_str = "-"

data_dir_path = base_dir.parent / 'data'
data_latest_str = "-"
if data_dir_path.exists():
    max_m = None
    for p in data_dir_path.rglob('*'):
        if p.is_file():
            try:
                m = p.stat().st_mtime
            except Exception:
                continue
            if max_m is None or m > max_m:
                max_m = m
    if max_m:
        data_latest_str = datetime.datetime.fromtimestamp(max_m).strftime("%Y-%m-%d %H:%M:%S")

st.sidebar.markdown(f"**ãƒ‡ãƒ¼ã‚¿æƒ…å ±**\n- çµæœãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°: {sel_mtime_str}\n- data æœ€çµ‚æ›´æ–°: {data_latest_str}")

# è¿½åŠ : outputs/results ã®ä¸­ã‹ã‚‰æœ€æ–°ã§ä¾¡æ ¼åˆ—ï¼ˆ'current_price' ã¾ãŸã¯ 'price'ï¼‰ã‚’æŒã¤CSVã‚’è‡ªå‹•æ¤œå‡ºã—ã¦èª­ã¿è¾¼ã¿
price_map = {}
price_file = None
candidates = sorted([str(p) for p in (results_dir.glob('*.csv'))], key=os.path.getmtime, reverse=True) if results_dir.exists() else []
for p in candidates:
    try:
        # read first line to detect timestamp metadata
        with open(p, 'r', encoding='utf-8') as fh:
            first = fh.readline()
        if first.startswith('retrieved_at,'):
            pf = pd.read_csv(p, skiprows=1)
        else:
            pf = pd.read_csv(p)

        if 'current_price' in pf.columns or 'price' in pf.columns:
            price_file = p
            # build price_map and stop at the first (newest) match
            if 'current_price' in pf.columns and 'ticker' in pf.columns:
                price_map = pd.Series(pf['current_price'].values, index=pf['ticker'].astype(str)).to_dict()
            elif 'price' in pf.columns and 'ticker' in pf.columns:
                price_map = pd.Series(pf['price'].values, index=pf['ticker'].astype(str)).to_dict()
            break
    except Exception:
        continue

# ä¾¡æ ¼ã§ã‚½ãƒ¼ãƒˆï¼ˆçµæœãƒ•ã‚¡ã‚¤ãƒ«ã« price åˆ—ã¾ãŸã¯åˆ¥é€”ä½œæˆã—ãŸ price_map ãŒã‚ã‚‹å ´åˆï¼‰
if 'price' in df.columns:
    df = df.sort_values('price').reset_index(drop=True)
elif price_map:
    # ãƒãƒƒãƒ—ã«åŸºã¥ã„ã¦ price åˆ—ã‚’ä½œã‚Šã‚½ãƒ¼ãƒˆ
    df = df.copy()
    df['price'] = df['ticker'].astype(str).map(price_map)
    df = df.sort_values('price').reset_index(drop=True)

st.sidebar.metric("æ¤œå‡ºéŠ˜æŸ„æ•°", len(df))

# éŠ˜æŸ„é¸æŠ
if 'ticker' not in df.columns:
    st.error("tickeråˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    st.stop()

ticker_list = df['ticker'].tolist()

# è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰é¸æŠ
display_mode = st.sidebar.radio("è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰", ["å˜ä¸€éŠ˜æŸ„", "10éŠ˜æŸ„ä¸€è¦§"])

if display_mode == "å˜ä¸€éŠ˜æŸ„":
    selected_ticker = st.sidebar.selectbox("éŠ˜æŸ„ã‚’é¸æŠ", ticker_list)
    selected_tickers = [selected_ticker]
else:
    # 10éŠ˜æŸ„ãšã¤ãƒšãƒ¼ã‚¸ãƒ³ã‚°
    total_pages = math.ceil(len(ticker_list) / 10)
    page = st.sidebar.number_input("ãƒšãƒ¼ã‚¸", min_value=1, max_value=total_pages, value=1, step=1)
    start_idx = (page - 1) * 10
    end_idx = min(start_idx + 10, len(ticker_list))
    selected_tickers = ticker_list[start_idx:end_idx]
    st.sidebar.info(f"ãƒšãƒ¼ã‚¸ {page}/{total_pages} (éŠ˜æŸ„ {start_idx+1}ã€œ{end_idx})")
    
    # 2åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§è¡¨ç¤º
    cols_per_row = 2

# ãƒ‡ãƒ¼ã‚¿å–å¾—
@st.cache_data(ttl=3600)
def fetch_data(ticker):
    try:
        data = yf.Ticker(ticker).history(period='2y', interval='1wk')
        if data.empty:
            return None
        return data
    except Exception as e:
        return None

# é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã«å¯¾ã—ã¦ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
if display_mode == "10éŠ˜æŸ„ä¸€è¦§":
    # 2åˆ—ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    for i in range(0, len(selected_tickers), cols_per_row):
        cols = st.columns(cols_per_row)
        for j, col in enumerate(cols):
            idx = i + j
            if idx >= len(selected_tickers):
                break
            ticker = selected_tickers[idx]
            
            with col:
                data = fetch_data(ticker)
                
                if data is None:
                    st.warning(f"{ticker}: ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
                    continue
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆï¼‰
                # ã¾ãš price_map ã«ä¾¡æ ¼ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆã—ã¦è¡¨ç¤ºï¼ˆãƒšãƒ¼ã‚¸åˆ‡æ›¿ã§å€¤ãŒå›ºå®šã•ã‚Œã‚‹å•é¡Œã‚’å›é¿ï¼‰
                latest_close = price_map.get(str(ticker)) if price_map else None
                if latest_close is None:
                    latest_close = data['Close'].iloc[-1]
                ma52 = data['Close'].rolling(52).mean().iloc[-1]


                st.markdown(f"**{ticker}**  Â¥{latest_close:,.0f}")
                
                # ãƒãƒ£ãƒ¼ãƒˆä½œæˆï¼ˆå°ã•ã‚ã‚µã‚¤ã‚ºï¼‰
                fig = make_subplots(
                    rows=2, cols=1,
                    shared_xaxes=True,
                    vertical_spacing=0.05,
                    row_heights=[0.75, 0.25]
                )
                
                # ãƒ­ãƒ¼ã‚½ã‚¯è¶³
                fig.add_trace(
                    go.Candlestick(
                        x=data.index,
                        open=data['Open'],
                        high=data['High'],
                        low=data['Low'],
                        close=data['Close'],
                        name='ä¾¡æ ¼',
                        increasing_line_color='red',
                        decreasing_line_color='blue',
                        showlegend=False
                    ),
                    row=1, col=1
                )
                
                # MA52
                fig.add_trace(
                    go.Scatter(
                        x=data.index,
                        y=data['Close'].rolling(52).mean(),
                        name='MA52',
                        line=dict(color='orange', width=1),
                        showlegend=False
                    ),
                    row=1, col=1
                )
                
                # å‡ºæ¥é«˜
                colors = ['red' if data['Close'].iloc[k] >= data['Open'].iloc[k] else 'blue' 
                          for k in range(len(data))]
                
                fig.add_trace(
                    go.Bar(
                        x=data.index,
                        y=data['Volume'],
                        marker_color=colors,
                        showlegend=False
                    ),
                    row=2, col=1
                )
                
                # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆï¼‰
                fig.update_layout(
                    height=300,
                    margin=dict(l=30, r=10, t=20, b=20),
                    xaxis_rangeslider_visible=False,
                    hovermode='x unified',
                    template='plotly_white',
                    showlegend=False,
                    font=dict(size=8)
                )
                
                fig.update_yaxes(title_text="", row=1, col=1)
                fig.update_yaxes(title_text="", row=2, col=1)
                fig.update_xaxes(showticklabels=False, row=1, col=1)
                fig.update_xaxes(showticklabels=False, row=2, col=1)
                
                st.plotly_chart(fig, use_container_width=True, key=f"chart_grid_{ticker}")

else:
    # å˜ä¸€éŠ˜æŸ„ãƒ¢ãƒ¼ãƒ‰
    for ticker in selected_tickers:
        data = fetch_data(ticker)
        
        if data is None:
            st.warning(f"{ticker}: ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            continue
        
        # åŒºåˆ‡ã‚Šç·š
        st.markdown("---")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        col1, col2, col3, col4, col5 = st.columns(5)
        
        # å˜ä¸€éŠ˜æŸ„ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ price_map ã®å€¤ã‚’å„ªå…ˆã™ã‚‹
        latest_close = price_map.get(str(ticker)) if price_map else None
        if latest_close is None:
            latest_close = data['Close'].iloc[-1]
        latest_volume = data['Volume'].iloc[-1]
        ma52 = data['Close'].rolling(52).mean().iloc[-1]
        change_pct = ((latest_close - data['Close'].iloc[-2]) / data['Close'].iloc[-2] * 100) if len(data) > 1 else 0
        
        with col1:
            st.metric("éŠ˜æŸ„", ticker)
        with col2:
            st.metric("æ ªä¾¡", f"Â¥{latest_close:,.2f}", f"{change_pct:+.2f}%")
        with col3:
            st.metric("å‡ºæ¥é«˜", f"{latest_volume:,.0f}")
        with col4:
            st.metric("52é€±MA", f"Â¥{ma52:,.2f}")
        with col5:
            ma_diff_pct = ((latest_close - ma52) / ma52 * 100)
            st.metric("MA52æ¯”", f"{ma_diff_pct:+.2f}%")
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥ã¾ãŸã¯æ›´æ–°æ™‚åˆ»ã‚’è¡¨ç¤º
        try:
            cache_path = base_dir.parent / 'data' / f"{ticker}.parquet"
            cache_info = None
            if cache_path.exists():
                try:
                    cdf = pd.read_parquet(cache_path)
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«æ—¥ä»˜ãŒã‚ã‚‹å ´åˆã¯æœ€çµ‚æ—¥ã‚’è¡¨ç¤º
                    if hasattr(cdf.index, 'max'):
                        idxmax = cdf.index.max()
                        cache_info = f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€çµ‚æ—¥: {pd.to_datetime(idxmax).date()}"
                except Exception:
                    cache_info = f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€çµ‚æ›´æ–°: {datetime.datetime.fromtimestamp(cache_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')}"
            if cache_info:
                st.caption(cache_info)
        except Exception:
            pass
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        fig = make_subplots(
            rows=2, cols=1,
            shared_xaxes=True,
            vertical_spacing=0.03,
            row_heights=[0.7, 0.3],
            subplot_titles=(f'{ticker} é€±è¶³ãƒãƒ£ãƒ¼ãƒˆ', 'å‡ºæ¥é«˜')
        )
        
        # ãƒ­ãƒ¼ã‚½ã‚¯è¶³
        fig.add_trace(
            go.Candlestick(
                x=data.index,
                open=data['Open'],
                high=data['High'],
                low=data['Low'],
                close=data['Close'],
                name='ä¾¡æ ¼',
                increasing_line_color='red',
                decreasing_line_color='blue'
            ),
            row=1, col=1
        )
        
        # MA52
        fig.add_trace(
            go.Scatter(
                x=data.index,
                y=data['Close'].rolling(52).mean(),
                name='MA52',
                line=dict(color='orange', width=2)
            ),
            row=1, col=1
        )
        
        # å‡ºæ¥é«˜
        colors = ['red' if data['Close'].iloc[i] >= data['Open'].iloc[i] else 'blue' 
                  for i in range(len(data))]
        
        fig.add_trace(
            go.Bar(
                x=data.index,
                y=data['Volume'],
                name='å‡ºæ¥é«˜',
                marker_color=colors,
                showlegend=False
            ),
            row=2, col=1
        )
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
        fig.update_layout(
            height=600,
            xaxis_rangeslider_visible=False,
            hovermode='x unified',
            template='plotly_white',
            showlegend=True
        )
        
        fig.update_yaxes(title_text="æ ªä¾¡ (Â¥)", row=1, col=1)
        fig.update_yaxes(title_text="å‡ºæ¥é«˜", row=2, col=1)
        fig.update_xaxes(title_text="æ—¥ä»˜", row=2, col=1)
        
        st.plotly_chart(fig, use_container_width=True, key=f"chart_{ticker}")
        
 # test